{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d1abf-5dfe-4172-bd43-fcc036c6933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "def normalize_annotations(annotation_dir, image_dir):\n",
    "    for annotation_file in os.listdir(annotation_dir):\n",
    "        if annotation_file.endswith('.txt'):\n",
    "            image_file = annotation_file.replace('.txt', '.jpg')  # или .png, в зависимости от формата ваших изображений\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "\n",
    "            # Проверяем, существует ли изображение\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Изображение не найдено для {annotation_file}\")\n",
    "                continue\n",
    "\n",
    "            # Получаем размеры изображения\n",
    "            from PIL import Image\n",
    "            with Image.open(image_path) as img:\n",
    "                width_of_image, height_of_image = img.size\n",
    "            \n",
    "            # Читаем аннотации\n",
    "            annotations = []\n",
    "            with open(os.path.join(annotation_dir, annotation_file), 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = list(map(float, line.strip().split()))\n",
    "                    cls = parts[0]  # класс\n",
    "                    x_min, y_min = parts[1], parts[2]\n",
    "                    x_max, y_max = parts[3], parts[4]\n",
    "\n",
    "                    # Нормализация   int(np.clip(box[0], 0, 1) * width)\n",
    "                    x_center = (x_min + x_max) / (2 * width_of_image)\n",
    "                    y_center = (y_min + y_max) / (2 * height_of_image)\n",
    "                    width = (x_max - x_min) / width_of_image\n",
    "                    width = np.clip(width, 0, 1)\n",
    "                    height = (y_max - y_min) / height_of_image\n",
    "                    height = np.clip(height, 0, 1)\n",
    "\n",
    "                    # Запись нормализованных аннотаций\n",
    "                    annotations.append(f\"{cls} {x_center} {y_center} {width} {height}\")\n",
    "\n",
    "            # Сохраняем нормализованные аннотации обратно в файл\n",
    "            with open(os.path.join(annotation_dir, annotation_file), 'w') as f:\n",
    "                for annotation in annotations:\n",
    "                    f.write(annotation + '\\n')\n",
    "\n",
    "# Пример вызова функции\n",
    "normalize_annotations(\"C:/Users/user/OTUS/proekt_work/ver_01/dataset/labels/train\", \"C:/Users/user/OTUS/proekt_work/ver_01/dataset/images/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99412c93-29df-423a-8ee0-aa4f7d6751d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "def normalize_annotations(annotation_dir, image_dir):\n",
    "    for annotation_file in os.listdir(annotation_dir):\n",
    "        if annotation_file.endswith('.txt'):\n",
    "            image_file = annotation_file.replace('.txt', '.jpg')  # или .png, в зависимости от формата ваших изображений\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "\n",
    "            # Проверяем, существует ли изображение\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Изображение не найдено для {annotation_file}\")\n",
    "                continue\n",
    "\n",
    "            # Получаем размеры изображения\n",
    "            from PIL import Image\n",
    "            with Image.open(image_path) as img:\n",
    "                width_of_image, height_of_image = img.size\n",
    "            \n",
    "            # Читаем аннотации\n",
    "            annotations = []\n",
    "            with open(os.path.join(annotation_dir, annotation_file), 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = list(map(float, line.strip().split()))\n",
    "                    cls = parts[0]  # класс\n",
    "                    x_min, y_min = parts[1], parts[2]\n",
    "                    x_max, y_max = parts[3], parts[4]\n",
    "\n",
    "                    # Нормализация   int(np.clip(box[0], 0, 1) * width)\n",
    "                    x_center = (x_min + x_max) / (2 * width_of_image)\n",
    "                    y_center = (y_min + y_max) / (2 * height_of_image)\n",
    "                    width = (x_max - x_min) / width_of_image\n",
    "                    width = np.clip(width, 0, 1)\n",
    "                    height = (y_max - y_min) / height_of_image\n",
    "                    height = np.clip(height, 0, 1)\n",
    "\n",
    "                    # Запись нормализованных аннотаций\n",
    "                    annotations.append(f\"{cls} {x_center} {y_center} {width} {height}\")\n",
    "\n",
    "            # Сохраняем нормализованные аннотации обратно в файл\n",
    "            with open(os.path.join(annotation_dir, annotation_file), 'w') as f:\n",
    "                for annotation in annotations:\n",
    "                    f.write(annotation + '\\n')\n",
    "\n",
    "# Пример вызова функции\n",
    "normalize_annotations(\"C:/Users/user/OTUS/proekt_work/ver_01/dataset/labels/val\", \"C:/Users/user/OTUS/proekt_work/ver_01/dataset/images/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b153a-71e5-46d7-81f5-fe975546d90d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef80d56-29b4-4ad8-bacd-ade3c79af977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b2cb42-a287-4b51-b9d5-fab16e4e1ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc9223a-953a-43de-a392-5457c31abf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af85ca44-f89d-40d7-a378-14b87e37e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Функция для отрисовки ограничивающих рамок на изображении\n",
    "def draw_bounding_boxes(image, boxes):\n",
    "    for box in boxes:\n",
    "        # Распаковать значения из строки\n",
    "        class_id, x_center, y_center, width, height = box\n",
    "        \n",
    "        # Преобразование координат в целочисленные значения\n",
    "        x_center = int(x_center * image.shape[1])\n",
    "        y_center = int(y_center * image.shape[0])\n",
    "        width = int(width * image.shape[1])\n",
    "        height = int(height * image.shape[0])\n",
    "\n",
    "        # Вычисление верхнего левого угла ограничивающей рамки\n",
    "        x1 = int(x_center - width / 2)\n",
    "        y1 = int(y_center - height / 2)\n",
    "        \n",
    "        # Определение нижнего правого угла\n",
    "        x2 = int(x_center + width / 2)\n",
    "        y2 = int(y_center + height / 2)\n",
    "\n",
    "        # Рисование ограничивающей рамки\n",
    "        color = (255, 0, 0)  # Цвет рамки (например, красный)\n",
    "        thickness = 2  # Толщина рамки\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\n",
    "        \n",
    "        # Добавление текста с идентификатором класса\n",
    "        cv2.putText(image, str(int(class_id)), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Загрузка изображения\n",
    "image = cv2.imread(\"C:/Users/user/OTUS/proekt_work/ver_01/dataset/images/train/0031.jpg\")\n",
    "import os\n",
    "\n",
    "def load_yolo_labels(label_dir, image_width, image_height):\n",
    "    boxes = []\n",
    "    \n",
    "    for label_file in os.listdir(label_dir):\n",
    "        if label_file.endswith(\".txt\"):  # Проверка на формат файла\n",
    "            with open(os.path.join(label_dir, label_file), 'r') as file:\n",
    "                for line in file.readlines():\n",
    "                    # Чтение строки аннотации\n",
    "                    class_id, x_center, y_center, width, height = map(float, line.split())\n",
    "                    # Заполнение массива для boxes\n",
    "                    boxes.append([class_id, x_center, y_center, width, height])\n",
    "    \n",
    "    return boxes\n",
    "# Данные для отрисовки (обратите внимание на формат)\n",
    "image_width = 512\n",
    "image_height = 512\n",
    "label_directory = \"C:/Users/user/OTUS/proekt_work/ver_01/dataset/labels/5\"\n",
    "\n",
    "boxes = load_yolo_labels(label_directory, image_width, image_height)\n",
    "\n",
    "# Вызов функции для отрисовки ограничивающих рамок\n",
    "result_image = draw_bounding_boxes(image, boxes)\n",
    "\n",
    "# Отображение результата\n",
    "cv2.imshow(\"Image with Bounding Boxes\", result_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b6f9fa-471e-49f5-b7cd-a1d9455f3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def normalize_annotations(annotation_dir, image_dir):\n",
    "    for annotation_file in os.listdir(annotation_dir):\n",
    "        if annotation_file.endswith('.txt'):\n",
    "            image_file = annotation_file.replace('.txt', '.jpg')  # или .png\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Изображение не найдено для {annotation_file}\")\n",
    "                continue\n",
    "\n",
    "            # Получаем размеры изображения\n",
    "            with Image.open(image_path) as img:\n",
    "                width_of_image, height_of_image = img.size\n",
    "            \n",
    "            annotations = []\n",
    "            with open(os.path.join(annotation_dir, annotation_file), 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = list(map(float, line.strip().split()))\n",
    "                    cls = parts[0]  # класс\n",
    "                    x_min, y_min = parts[1], parts[2]\n",
    "                    x_max, y_max = parts[3], parts[4]\n",
    "\n",
    "                    # Проверяем, что координаты положительные и не выходят за пределы\n",
    "                    if x_min < 0 or y_min < 0 or x_max > width_of_image or y_max > height_of_image:\n",
    "                        print(f\"Ошибка координат в {annotation_file}: {x_min}, {y_min}, {x_max}, {y_max}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Нормализация\n",
    "                    x_center = (x_min + x_max) / (2 * width_of_image)\n",
    "                    y_center = (y_min + y_max) / (2 * height_of_image)\n",
    "                    width = (x_max - x_min) / width_of_image\n",
    "                    height = (y_max - y_min) / height_of_image\n",
    "\n",
    "                    if not (0 <= x_center <= 1 and 0 <= y_center <= 1 and 0 < width <= 1 and 0 < height <= 1):\n",
    "                        print(f\"Некорректные нормализованные значения в {annotation_file}: {x_center}, {y_center}, {width}, {height}\")\n",
    "                        continue\n",
    "\n",
    "                    annotations.append(f\"{cls} {x_center} {y_center} {width} {height}\")\n",
    "\n",
    "            with open(os.path.join(annotation_dir, annotation_file), 'w') as f:\n",
    "                for annotation in annotations:\n",
    "                    f.write(annotation + '\\n')\n",
    "\n",
    "# Пример вызова функции\n",
    "normalize_annotations(\"C:/Users/user/OTUS/proekt_work/ver_01/dataset/labels/train\", \"C:/Users/user/OTUS/proekt_work/ver_01/dataset/images/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feac4f5-bf98-48fa-9edf-f0877edc582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def check_annotations(annotation_dir, image_width, image_height):\n",
    "    for filename in os.listdir(annotation_dir):\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(annotation_dir, filename), 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) < 5:\n",
    "                        print(f\"Error: insufficient data in {filename}: {line}\")\n",
    "                        continue\n",
    "                    cls, x_center, y_center, width, height = map(float, parts)\n",
    "                    if not (0 <= x_center <= 1) or not (0 <= y_center <= 1) or not (0 <= width <= 1) or not (0 <= height <= 1):\n",
    "                        print(f\"Warning: non-normalized values in {filename}: {line}\")\n",
    "\n",
    "# Пример вызова функции\n",
    "check_annotations(\"C:/Users/user/OTUS/proekt_work/ver_01/dataset/labels/train\", 512, 512)  # Замените на ваши размеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41bbf24-7ae5-497c-a730-064a07c19ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
